=> merge config from configs/resnet18_base.yaml
[32m[2023-03-16 09:17:58 resnet18][33m(main.py 239)[39m: INFO Full config saved to output/resnet18/config.yaml
[32m[2023-03-16 09:17:58 resnet18][33m(main.py 242)[39m: INFO AUG:
  COLOR_JITTER: 0.4
  RAND_AUGMENT: rand-m9-mstd0.5-inc1
BASE:
- ''
DATA:
  BATCH_SIZE: 1024
  DATASET: cifar10
  DATA_PATH: ''
  IMG_SIZE: 32
  INTERPOLATION: bicubic
  NUM_WORKERS: 8
  PIN_MEMORY: true
EVAL_MODE: false
MODEL:
  DROP_RATE: 0.0
  NAME: resnet18
  NUM_CLASSES: 10
  RESNET: {}
  RESUME: ''
OUTPUT: output/resnet18
PRINT_FREQ: 500
SAVE_FREQ: 1
SEED: 0
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  EPOCHS: 100
  LR: 0.3
  LR_SCHEDULER:
    NAME: cosine
  MIN_LR: 0.03
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  WARMUP_EPOCHS: 20
  WARMUP_LR: 0.03
[32m[2023-03-16 09:17:58 resnet18][33m(main.py 243)[39m: INFO {"cfg": "configs/resnet18_base.yaml", "opts": null, "batch_size": null, "data_path": null, "resume": null, "output": "output", "eval": false, "throughput": false}
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
[32m[2023-03-16 09:18:05 resnet18][33m(main.py 73)[39m: INFO N/A indicates a possibly missing statistic due to how the module was called. Missing values are still included in the parent's total.
ResNet18(
  #params: 11.18M, #flops: 0.56G
  (conv1): Conv2d(
    3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
    #params: 1.73K, #flops: 1.77M
  )
  (bn1): BatchNorm2d(
    64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
    #params: 0.13K, #flops: 0.33M
  )
  (layer1): Sequential(
    #params: 0.15M, #flops: 0.15G
    (0): ResNetBlock(
      #params: 74.11K, #flops: 76.15M
      (conv1): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        #params: 36.93K, #flops: 37.75M
      )
      (bn1): BatchNorm2d(
        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 0.13K, #flops: 0.33M
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        #params: 36.93K, #flops: 37.75M
      )
      (bn2): BatchNorm2d(
        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 0.13K, #flops: 0.33M
      )
      (shortcut): Sequential(#params: 0, #flops: N/A)
    )
    (1): ResNetBlock(
      #params: 74.11K, #flops: 76.15M
      (conv1): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        #params: 36.93K, #flops: 37.75M
      )
      (bn1): BatchNorm2d(
        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 0.13K, #flops: 0.33M
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        #params: 36.93K, #flops: 37.75M
      )
      (bn2): BatchNorm2d(
        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 0.13K, #flops: 0.33M
      )
      (shortcut): Sequential(#params: 0, #flops: N/A)
    )
  )
  (layer2): Sequential(
    #params: 0.53M, #flops: 0.14G
    (0): ResNetBlock(
      #params: 0.23M, #flops: 59.21M
      (conv1): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)
        #params: 73.86K, #flops: 18.87M
      )
      (bn1): BatchNorm2d(
        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 0.26K, #flops: 0.16M
      )
      (conv2): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        #params: 0.15M, #flops: 37.75M
      )
      (bn2): BatchNorm2d(
        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 0.26K, #flops: 0.16M
      )
      (shortcut): Sequential(
        #params: 8.58K, #flops: 2.26M
        (0): Conv2d(
          64, 128, kernel_size=(1, 1), stride=(2, 2)
          #params: 8.32K, #flops: 2.1M
        )
        (1): BatchNorm2d(
          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
          #params: 0.26K, #flops: 0.16M
        )
      )
    )
    (1): ResNetBlock(
      #params: 0.3M, #flops: 75.83M
      (conv1): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        #params: 0.15M, #flops: 37.75M
      )
      (bn1): BatchNorm2d(
        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 0.26K, #flops: 0.16M
      )
      (conv2): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        #params: 0.15M, #flops: 37.75M
      )
      (bn2): BatchNorm2d(
        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 0.26K, #flops: 0.16M
      )
      (shortcut): Sequential(#params: 0, #flops: N/A)
    )
  )
  (layer3): Sequential(
    #params: 2.1M, #flops: 0.13G
    (0): ResNetBlock(
      #params: 0.92M, #flops: 58.97M
      (conv1): Conv2d(
        128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)
        #params: 0.3M, #flops: 18.87M
      )
      (bn1): BatchNorm2d(
        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 0.51K, #flops: 81.92K
      )
      (conv2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        #params: 0.59M, #flops: 37.75M
      )
      (bn2): BatchNorm2d(
        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 0.51K, #flops: 81.92K
      )
      (shortcut): Sequential(
        #params: 33.54K, #flops: 2.18M
        (0): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(2, 2)
          #params: 33.02K, #flops: 2.1M
        )
        (1): BatchNorm2d(
          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
          #params: 0.51K, #flops: 81.92K
        )
      )
    )
    (1): ResNetBlock(
      #params: 1.18M, #flops: 75.66M
      (conv1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        #params: 0.59M, #flops: 37.75M
      )
      (bn1): BatchNorm2d(
        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 0.51K, #flops: 81.92K
      )
      (conv2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        #params: 0.59M, #flops: 37.75M
      )
      (bn2): BatchNorm2d(
        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 0.51K, #flops: 81.92K
      )
      (shortcut): Sequential(#params: 0, #flops: N/A)
    )
  )
  (layer4): Sequential(
    #params: 8.4M, #flops: 0.13G
    (0): ResNetBlock(
      #params: 3.67M, #flops: 58.84M
      (conv1): Conv2d(
        256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)
        #params: 1.18M, #flops: 18.87M
      )
      (bn1): BatchNorm2d(
        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 1.02K, #flops: 40.96K
      )
      (conv2): Conv2d(
        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        #params: 2.36M, #flops: 37.75M
      )
      (bn2): BatchNorm2d(
        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 1.02K, #flops: 40.96K
      )
      (shortcut): Sequential(
        #params: 0.13M, #flops: 2.14M
        (0): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2)
          #params: 0.13M, #flops: 2.1M
        )
        (1): BatchNorm2d(
          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
          #params: 1.02K, #flops: 40.96K
        )
      )
    )
    (1): ResNetBlock(
      #params: 4.72M, #flops: 75.58M
      (conv1): Conv2d(
        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        #params: 2.36M, #flops: 37.75M
      )
      (bn1): BatchNorm2d(
        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 1.02K, #flops: 40.96K
      )
      (conv2): Conv2d(
        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        #params: 2.36M, #flops: 37.75M
      )
      (bn2): BatchNorm2d(
        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 1.02K, #flops: 40.96K
      )
      (shortcut): Sequential(#params: 0, #flops: N/A)
    )
  )
  (linear): Linear(
    in_features=512, out_features=10, bias=True
    #params: 5.13K, #flops: 5.12K
  )
)
[32m[2023-03-16 09:18:05 resnet18][33m(main.py 74)[39m: INFO number of params: 11.178698 M
[32m[2023-03-16 09:18:05 resnet18][33m(main.py 75)[39m: INFO flops: 558.49472 MFLOPS
[32m[2023-03-16 09:18:05 resnet18][33m(main.py 91)[39m: INFO Start training
Unsupported operator aten::add_ encountered 28 time(s)
Unsupported operator aten::avg_pool2d encountered 1 time(s)
The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
layer1.0.shortcut, layer1.1.shortcut, layer2.1.shortcut, layer3.1.shortcut, layer4.1.shortcut









 92%|█████████████████████████████████████████▎   | 45/49 [00:19<00:01,  2.54it/s]
[32m[2023-03-16 09:18:26 resnet18][33m(main.py 159)[39m: INFO Train: [0/100]	lr 0.300000	time 0.3309 (0.4254)	loss 2.1534 (6.1363)	Acc@1 17.217 (14.624)	Mem 5250MB
[32m[2023-03-16 09:18:26 resnet18][33m(main.py 168)[39m: INFO EPOCH 0 training takes 0:00:20
[32m[2023-03-16 09:18:26 resnet18][33m(main.py 95)[39m: INFO  * Train Acc 14.624 Train Loss 6.136

[32m[2023-03-16 09:18:26 resnet18][33m(main.py 96)[39m: INFO Accuracy of the network on the 50000 train images: 14.6%
[32m[2023-03-16 09:18:28 resnet18][33m(main.py 201)[39m: INFO Validate: 	Time 0.085 (0.195)	Loss 2.1174 (2.1345)	Acc@1 18.367 (19.110)	Mem 5250MB
[32m[2023-03-16 09:18:28 resnet18][33m(main.py 100)[39m: INFO  * Val Acc 19.110 Val Loss 2.135
[32m[2023-03-16 09:18:28 resnet18][33m(main.py 101)[39m: INFO Accuracy of the network on the 10000 val images: 19.1%
[32m[2023-03-16 09:18:28 resnet18][33m(load_save.py 48)[39m: INFO output/resnet18/ckpt_best.pth saving......
  0%|                                                      | 0/49 [00:00<?, ?it/s]
[32m[2023-03-16 09:18:28 resnet18][33m(load_save.py 50)[39m: INFO output/resnet18/ckpt_best.pth saved !!!










 94%|██████████████████████████████████████████▏  | 46/49 [00:19<00:01,  2.50it/s]
[32m[2023-03-16 09:18:49 resnet18][33m(main.py 159)[39m: INFO Train: [1/100]	lr 0.299926	time 0.3369 (0.4247)	loss 2.0408 (2.1000)	Acc@1 22.995 (19.230)	Mem 5250MB
[32m[2023-03-16 09:18:49 resnet18][33m(main.py 168)[39m: INFO EPOCH 1 training takes 0:00:20
[32m[2023-03-16 09:18:49 resnet18][33m(main.py 95)[39m: INFO  * Train Acc 19.230 Train Loss 2.100

[32m[2023-03-16 09:18:49 resnet18][33m(main.py 96)[39m: INFO Accuracy of the network on the 50000 train images: 19.2%
[32m[2023-03-16 09:18:51 resnet18][33m(main.py 201)[39m: INFO Validate: 	Time 0.088 (0.198)	Loss 2.0770 (2.0911)	Acc@1 17.857 (19.830)	Mem 5250MB
[32m[2023-03-16 09:18:51 resnet18][33m(main.py 100)[39m: INFO  * Val Acc 19.830 Val Loss 2.091
[32m[2023-03-16 09:18:51 resnet18][33m(main.py 101)[39m: INFO Accuracy of the network on the 10000 val images: 19.8%
[32m[2023-03-16 09:18:51 resnet18][33m(load_save.py 48)[39m: INFO output/resnet18/ckpt_best.pth saving......
[32m[2023-03-16 09:18:52 resnet18][33m(load_save.py 50)[39m: INFO output/resnet18/ckpt_best.pth saved !!!
[32m[2023-03-16 09:18:52 resnet18][33m(main.py 109)[39m: INFO Max accuracy: 19.83%










 96%|███████████████████████████████████████████▏ | 47/49 [00:20<00:00,  2.47it/s]
[32m[2023-03-16 09:19:13 resnet18][33m(main.py 159)[39m: INFO Train: [2/100]	lr 0.299704	time 0.3396 (0.4332)	loss 1.9688 (2.0344)	Acc@1 22.877 (20.910)	Mem 5250MB
[32m[2023-03-16 09:19:13 resnet18][33m(main.py 168)[39m: INFO EPOCH 2 training takes 0:00:21
[32m[2023-03-16 09:19:13 resnet18][33m(main.py 95)[39m: INFO  * Train Acc 20.910 Train Loss 2.034

[32m[2023-03-16 09:19:13 resnet18][33m(main.py 96)[39m: INFO Accuracy of the network on the 50000 train images: 20.9%
[32m[2023-03-16 09:19:15 resnet18][33m(main.py 201)[39m: INFO Validate: 	Time 0.088 (0.203)	Loss 1.9879 (2.0123)	Acc@1 19.388 (21.440)	Mem 5250MB
[32m[2023-03-16 09:19:15 resnet18][33m(main.py 100)[39m: INFO  * Val Acc 21.440 Val Loss 2.012
[32m[2023-03-16 09:19:15 resnet18][33m(main.py 101)[39m: INFO Accuracy of the network on the 10000 val images: 21.4%
[32m[2023-03-16 09:19:15 resnet18][33m(load_save.py 48)[39m: INFO output/resnet18/ckpt_best.pth saving......
[32m[2023-03-16 09:19:16 resnet18][33m(load_save.py 50)[39m: INFO output/resnet18/ckpt_best.pth saved !!!
[32m[2023-03-16 09:19:16 resnet18][33m(main.py 109)[39m: INFO Max accuracy: 21.44%










 96%|███████████████████████████████████████████▏ | 47/49 [00:20<00:00,  2.47it/s]
[32m[2023-03-16 09:19:37 resnet18][33m(main.py 159)[39m: INFO Train: [3/100]	lr 0.299334	time 0.3400 (0.4299)	loss 1.8719 (1.9304)	Acc@1 27.594 (24.686)	Mem 5250MB
[32m[2023-03-16 09:19:37 resnet18][33m(main.py 168)[39m: INFO EPOCH 3 training takes 0:00:21
[32m[2023-03-16 09:19:37 resnet18][33m(main.py 95)[39m: INFO  * Train Acc 24.686 Train Loss 1.930

[32m[2023-03-16 09:19:37 resnet18][33m(main.py 96)[39m: INFO Accuracy of the network on the 50000 train images: 24.7%
[32m[2023-03-16 09:19:39 resnet18][33m(main.py 201)[39m: INFO Validate: 	Time 0.087 (0.196)	Loss 1.8791 (1.9009)	Acc@1 25.510 (25.290)	Mem 5250MB
[32m[2023-03-16 09:19:39 resnet18][33m(main.py 100)[39m: INFO  * Val Acc 25.290 Val Loss 1.901
[32m[2023-03-16 09:19:39 resnet18][33m(main.py 101)[39m: INFO Accuracy of the network on the 10000 val images: 25.3%
[32m[2023-03-16 09:19:39 resnet18][33m(load_save.py 48)[39m: INFO output/resnet18/ckpt_best.pth saving......
[32m[2023-03-16 09:19:40 resnet18][33m(load_save.py 50)[39m: INFO output/resnet18/ckpt_best.pth saved !!!
[32m[2023-03-16 09:19:40 resnet18][33m(main.py 109)[39m: INFO Max accuracy: 25.29%




Traceback (most recent call last):
  File "/home/vanessaxteo/sp23-nmep-hw1/main.py", line 245, in <module>
    main(config)
  File "/home/vanessaxteo/sp23-nmep-hw1/main.py", line 94, in main
    train_acc1, train_loss = train_one_epoch(config, model, criterion, data_loader_train, optimizer, epoch)
  File "/home/vanessaxteo/sp23-nmep-hw1/main.py", line 148, in train_one_epoch
    loss.backward()
  File "/home/vanessaxteo/miniconda3/envs/vision-zoo/lib/python3.10/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/vanessaxteo/miniconda3/envs/vision-zoo/lib/python3.10/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt