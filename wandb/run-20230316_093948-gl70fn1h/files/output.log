=> merge config from configs/resnet18_base.yaml
[32m[2023-03-16 09:39:51 resnet18][33m(main.py 239)[39m: INFO Full config saved to output/resnet18/config.yaml
[32m[2023-03-16 09:39:51 resnet18][33m(main.py 242)[39m: INFO AUG:
  COLOR_JITTER: 0.4
  RAND_AUGMENT: rand-m9-mstd0.5-inc1
BASE:
- ''
DATA:
  BATCH_SIZE: 1024
  DATASET: cifar10
  DATA_PATH: ''
  IMG_SIZE: 32
  INTERPOLATION: bicubic
  NUM_WORKERS: 8
  PIN_MEMORY: true
EVAL_MODE: false
MODEL:
  DROP_RATE: 0.0
  NAME: resnet18
  NUM_CLASSES: 10
  RESNET: {}
  RESUME: ''
OUTPUT: output/resnet18
PRINT_FREQ: 500
SAVE_FREQ: 1
SEED: 0
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  EPOCHS: 100
  LR: 0.0003
  LR_SCHEDULER:
    NAME: cosine
  MIN_LR: 3.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  START_EPOCH: 0
  WARMUP_EPOCHS: 20
  WARMUP_LR: 3.0e-05
[32m[2023-03-16 09:39:51 resnet18][33m(main.py 243)[39m: INFO {"cfg": "configs/resnet18_base.yaml", "opts": null, "batch_size": null, "data_path": null, "resume": null, "output": "output", "eval": false, "throughput": false}
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Unsupported operator aten::add_ encountered 28 time(s)
Unsupported operator aten::avg_pool2d encountered 1 time(s)
The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
layer1.0.shortcut, layer1.1.shortcut, layer2.1.shortcut, layer3.1.shortcut, layer4.1.shortcut
  0%|                                                    | 0/49 [00:00<?, ?it/s]
[32m[2023-03-16 09:39:57 resnet18][33m(main.py 73)[39m: INFO N/A indicates a possibly missing statistic due to how the module was called. Missing values are still included in the parent's total.
ResNet18(
  #params: 11.18M, #flops: 0.56G
  (conv1): Conv2d(
    3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
    #params: 1.73K, #flops: 1.77M
  )
  (bn1): BatchNorm2d(
    64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
    #params: 0.13K, #flops: 0.33M
  )
  (layer1): Sequential(
    #params: 0.15M, #flops: 0.15G
    (0): ResNetBlock(
      #params: 74.11K, #flops: 76.15M
      (conv1): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        #params: 36.93K, #flops: 37.75M
      )
      (bn1): BatchNorm2d(
        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 0.13K, #flops: 0.33M
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        #params: 36.93K, #flops: 37.75M
      )
      (bn2): BatchNorm2d(
        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 0.13K, #flops: 0.33M
      )
      (shortcut): Sequential(#params: 0, #flops: N/A)
    )
    (1): ResNetBlock(
      #params: 74.11K, #flops: 76.15M
      (conv1): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        #params: 36.93K, #flops: 37.75M
      )
      (bn1): BatchNorm2d(
        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 0.13K, #flops: 0.33M
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        #params: 36.93K, #flops: 37.75M
      )
      (bn2): BatchNorm2d(
        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 0.13K, #flops: 0.33M
      )
      (shortcut): Sequential(#params: 0, #flops: N/A)
    )
  )
  (layer2): Sequential(
    #params: 0.53M, #flops: 0.14G
    (0): ResNetBlock(
      #params: 0.23M, #flops: 59.21M
      (conv1): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)
        #params: 73.86K, #flops: 18.87M
      )
      (bn1): BatchNorm2d(
        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 0.26K, #flops: 0.16M
      )
      (conv2): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        #params: 0.15M, #flops: 37.75M
      )
      (bn2): BatchNorm2d(
        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 0.26K, #flops: 0.16M
      )
      (shortcut): Sequential(
        #params: 8.58K, #flops: 2.26M
        (0): Conv2d(
          64, 128, kernel_size=(1, 1), stride=(2, 2)
          #params: 8.32K, #flops: 2.1M
        )
        (1): BatchNorm2d(
          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
          #params: 0.26K, #flops: 0.16M
        )
      )
    )
    (1): ResNetBlock(
      #params: 0.3M, #flops: 75.83M
      (conv1): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        #params: 0.15M, #flops: 37.75M
      )
      (bn1): BatchNorm2d(
        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 0.26K, #flops: 0.16M
      )
      (conv2): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        #params: 0.15M, #flops: 37.75M
      )
      (bn2): BatchNorm2d(
        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 0.26K, #flops: 0.16M
      )
      (shortcut): Sequential(#params: 0, #flops: N/A)
    )
  )
  (layer3): Sequential(
    #params: 2.1M, #flops: 0.13G
    (0): ResNetBlock(
      #params: 0.92M, #flops: 58.97M
      (conv1): Conv2d(
        128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)
        #params: 0.3M, #flops: 18.87M
      )
      (bn1): BatchNorm2d(
        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 0.51K, #flops: 81.92K
      )
      (conv2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        #params: 0.59M, #flops: 37.75M
      )
      (bn2): BatchNorm2d(
        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 0.51K, #flops: 81.92K
      )
      (shortcut): Sequential(
        #params: 33.54K, #flops: 2.18M
        (0): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(2, 2)
          #params: 33.02K, #flops: 2.1M
        )
        (1): BatchNorm2d(
          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
          #params: 0.51K, #flops: 81.92K
        )
      )
    )
    (1): ResNetBlock(
      #params: 1.18M, #flops: 75.66M
      (conv1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        #params: 0.59M, #flops: 37.75M
      )
      (bn1): BatchNorm2d(
        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 0.51K, #flops: 81.92K
      )
      (conv2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        #params: 0.59M, #flops: 37.75M
      )
      (bn2): BatchNorm2d(
        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 0.51K, #flops: 81.92K
      )
      (shortcut): Sequential(#params: 0, #flops: N/A)
    )
  )
  (layer4): Sequential(
    #params: 8.4M, #flops: 0.13G
    (0): ResNetBlock(
      #params: 3.67M, #flops: 58.84M
      (conv1): Conv2d(
        256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)
        #params: 1.18M, #flops: 18.87M
      )
      (bn1): BatchNorm2d(
        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 1.02K, #flops: 40.96K
      )
      (conv2): Conv2d(
        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        #params: 2.36M, #flops: 37.75M
      )
      (bn2): BatchNorm2d(
        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 1.02K, #flops: 40.96K
      )
      (shortcut): Sequential(
        #params: 0.13M, #flops: 2.14M
        (0): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2)
          #params: 0.13M, #flops: 2.1M
        )
        (1): BatchNorm2d(
          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
          #params: 1.02K, #flops: 40.96K
        )
      )
    )
    (1): ResNetBlock(
      #params: 4.72M, #flops: 75.58M
      (conv1): Conv2d(
        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        #params: 2.36M, #flops: 37.75M
      )
      (bn1): BatchNorm2d(
        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 1.02K, #flops: 40.96K
      )
      (conv2): Conv2d(
        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        #params: 2.36M, #flops: 37.75M
      )
      (bn2): BatchNorm2d(
        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True
        #params: 1.02K, #flops: 40.96K
      )
      (shortcut): Sequential(#params: 0, #flops: N/A)
    )
  )
  (linear): Linear(
    in_features=512, out_features=10, bias=True
    #params: 5.13K, #flops: 5.12K
  )
)
[32m[2023-03-16 09:39:57 resnet18][33m(main.py 74)[39m: INFO number of params: 11.178698 M
[32m[2023-03-16 09:39:57 resnet18][33m(main.py 75)[39m: INFO flops: 558.49472 MFLOPS










 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 45/49 [00:19<00:01,  2.52it/s]
[32m[2023-03-16 09:40:18 resnet18][33m(main.py 159)[39m: INFO Train: [0/100]	lr 0.000300	time 0.3345 (0.4276)	loss 2.1920 (2.2502)	Acc@1 19.575 (15.634)	Mem 5207MB
[32m[2023-03-16 09:40:18 resnet18][33m(main.py 168)[39m: INFO EPOCH 0 training takes 0:00:21
[32m[2023-03-16 09:40:18 resnet18][33m(main.py 95)[39m: INFO  * Train Acc 15.634 Train Loss 2.250
[32m[2023-03-16 09:40:18 resnet18][33m(main.py 96)[39m: INFO Accuracy of the network on the 50000 train images: 15.6%
[32m[2023-03-16 09:40:20 resnet18][33m(main.py 201)[39m: INFO Validate: 	Time 0.086 (0.198)	Loss 2.1470 (2.1540)	Acc@1 22.449 (22.810)	Mem 5207MB
[32m[2023-03-16 09:40:20 resnet18][33m(main.py 100)[39m: INFO  * Val Acc 22.810 Val Loss 2.154
[32m[2023-03-16 09:40:20 resnet18][33m(main.py 101)[39m: INFO Accuracy of the network on the 10000 val images: 22.8%
[32m[2023-03-16 09:40:20 resnet18][33m(load_save.py 48)[39m: INFO output/resnet18/ckpt_best.pth saving......
  2%|â–‰                                           | 1/49 [00:01<01:25,  1.79s/it]
[32m[2023-03-16 09:40:21 resnet18][33m(load_save.py 50)[39m: INFO output/resnet18/ckpt_best.pth saved !!!









 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 46/49 [00:19<00:01,  2.48it/s]
[32m[2023-03-16 09:40:42 resnet18][33m(main.py 159)[39m: INFO Train: [1/100]	lr 0.000300	time 0.3392 (0.4279)	loss 1.9784 (2.0888)	Acc@1 29.835 (23.394)	Mem 5207MB
[32m[2023-03-16 09:40:42 resnet18][33m(main.py 168)[39m: INFO EPOCH 1 training takes 0:00:21
[32m[2023-03-16 09:40:42 resnet18][33m(main.py 95)[39m: INFO  * Train Acc 23.394 Train Loss 2.089

[32m[2023-03-16 09:40:42 resnet18][33m(main.py 96)[39m: INFO Accuracy of the network on the 50000 train images: 23.4%
[32m[2023-03-16 09:40:44 resnet18][33m(main.py 201)[39m: INFO Validate: 	Time 0.088 (0.196)	Loss 1.9716 (1.9828)	Acc@1 29.082 (29.360)	Mem 5207MB
[32m[2023-03-16 09:40:44 resnet18][33m(main.py 100)[39m: INFO  * Val Acc 29.360 Val Loss 1.983
[32m[2023-03-16 09:40:44 resnet18][33m(main.py 101)[39m: INFO Accuracy of the network on the 10000 val images: 29.4%
[32m[2023-03-16 09:40:44 resnet18][33m(load_save.py 48)[39m: INFO output/resnet18/ckpt_best.pth saving......
[32m[2023-03-16 09:40:44 resnet18][33m(load_save.py 50)[39m: INFO output/resnet18/ckpt_best.pth saved !!!
[32m[2023-03-16 09:40:44 resnet18][33m(main.py 109)[39m: INFO Max accuracy: 29.36%

Traceback (most recent call last):
  File "/home/vanessaxteo/sp23-nmep-hw1/main.py", line 245, in <module>
    main(config)
  File "/home/vanessaxteo/sp23-nmep-hw1/main.py", line 94, in main
    train_acc1, train_loss = train_one_epoch(config, model, criterion, data_loader_train, optimizer, epoch)
  File "/home/vanessaxteo/sp23-nmep-hw1/main.py", line 152, in train_one_epoch
    loss_meter.update(loss.item(), targets.size(0))
KeyboardInterrupt